# Command: /bootstrap
description = "Bootstrap AI development infrastructure for any project (Intelligent Edition)"
prompt = """
# Gemini Agent System Bootstrap - Intelligent Workflow Edition

**Version**: 2.1 (Intelligent Edition)
**Purpose**: Create a self-aware, adaptive agent system with contextual intelligence

This bootstrap creates an intelligent Gemini agent system with:

- **Context-Aware Analysis** - Agents understand project patterns before acting
- **Adaptive Checkpoints** - Workflow depth adjusts to task complexity
- **Knowledge Synthesis** - Automatic pattern extraction and documentation
- **Intelligent Tool Selection** - MCP tool usage based on task requirements
- **Quality Enforcement** - Multi-tier validation with graceful degradation
- **Self-Documenting** - Captures learnings for future agent sessions
- **Cross-Agent Memory** - Shared knowledge base evolves over time

**Execution**: Run this entire prompt with Gemini in your project root.
**Philosophy**: Agents should learn from the codebase, not just execute commands.

---

## BOOTSTRAP PHILOSOPHY

### Intelligence Principles

1. **Context First, Code Second**
   - Read existing patterns before creating new ones
   - Understand project conventions from actual code
   - Adapt to project's unique architectural style

2. **Adaptive Complexity**
   - Simple tasks get streamlined workflows
   - Complex features trigger deep analysis
   - Checkpoint count scales with complexity:
     - **Simple**: 6 checkpoints
     - **Medium**: 8 checkpoints
     - **Complex**: 10+ checkpoints

3. **Knowledge Accumulation**
   - Every feature adds to project guides
   - Patterns become reusable templates
   - Future agents inherit all learnings

4. **Graceful Degradation**
   - Missing tools trigger fallback strategies
   - Optional features don't block progress
   - Clear communication when capabilities limited

---

## PHASE 1: INTELLIGENT PROJECT ANALYSIS

### Step 1.1: Deep Codebase Understanding

**Don't just detect - understand WHY patterns exist:**

```bash
# Detect project structure
ls -la
find . -type f -name "*.py" -o -name "*.ts" -o -name "*.tsx" -o -name "*.vue" | head -20

# Read configuration to understand philosophy
cat pyproject.toml package.json 2>/dev/null
```

**Key questions to answer:**

1. **Architecture Philosophy**:
   - Is this a monolith or microservices?
   - Does it use domain-driven design?
   - What's the layering strategy (plugin -> middleware -> route)?

2. **Type System Approach**:
   - Strict typing or dynamic?
   - Type hints usage patterns?
   - Validation strategy (runtime vs compile-time)?

3. **Testing Philosophy**:
   - TDD or test-after?
   - Unit vs integration test ratio?
   - Coverage expectations?

4. **Code Organization**:
   - Feature-based or layer-based folders?
   - Naming conventions (verb_noun vs noun_verb)?
   - File size preferences?

**Document findings in workspace for future reference.**

### Step 1.2: Extract Existing Patterns

**Read actual code to discover patterns:**

```bash
# Find plugin patterns
find src/ -type f -name "*plugin*" -o -name "*middleware*" -o -name "*extension*"

# Find service patterns
find src/ -type f -name "*service*" -o -name "*manager*" -o -name "*handler*"

# Find configuration patterns
find src/ -type f -name "*config*" -o -name "*settings*"

# Find error handling patterns
grep -r "class.*Error" src/ | head -10
grep -r "raise.*from" src/ | head -10

# Find async patterns
grep -r "async def" src/ | wc -l
grep -r "await" src/ | wc -l
```

**Pattern Analysis**:

1. **Read 3-5 example files** for each pattern type
2. **Identify common structure** (class hierarchy, decorators, mixins)
3. **Note naming conventions** (verbs, prefixes, suffixes)
4. **Extract docstring style** (Google, NumPy, reStructuredText)
5. **Understand error handling** (custom exceptions, context managers)

### Step 1.3: Analyze Testing Patterns

**Learn from existing tests:**

```bash
# Find test organization
find tests/ -type f -name "test_*.py" -o -name "*_test.py" | head -20

# Read a sample test file
cat tests/unit/test_*.py 2>/dev/null | head -100
cat tests/integration/test_*.py 2>/dev/null | head -100

# Analyze test structure
grep -r "def test_" tests/ | wc -l
grep -r "class Test" tests/ | wc -l
grep -r "@pytest.fixture" tests/ | wc -l
```

**Test Pattern Questions**:

1. Function-based or class-based tests?
2. Fixture organization (conftest.py or inline)?
3. Mocking strategy (unittest.mock, pytest-mock)?
4. Async test patterns?
5. Integration test setup (databases, external services)?

### Step 1.4: Discover Documentation Style

```bash
# Find existing documentation
find docs/ -name "*.md" -o -name "*.rst" 2>/dev/null | head -20

# Read doc examples
cat docs/*.md 2>/dev/null | head -200

# Check for README patterns
cat README.md | head -100
```

**Documentation Intelligence**:

1. **Tone**: Formal vs conversational?
2. **Examples**: Code-heavy or conceptual?
3. **Organization**: Task-based or reference-based?
4. **Depth**: High-level overview or detailed tutorials?

---

## PHASE 2: INTELLIGENT MCP TOOL DETECTION

Create **adaptive** MCP tool detection with fallback strategies:

```bash
mkdir -p .gemini/tools
cat > .gemini/tools/detect_mcp.py << 'EOF'
#!/usr/bin/env python3
\"\"\"Intelligent MCP tool detection with capability mapping.\"\"\"

from dataclasses import dataclass
from enum import Enum


class ToolCapability(Enum):
    \"\"\"MCP tool capability categories.\"\"\"
    REASONING = "reasoning"  # Deep thinking tools
    RESEARCH = "research"    # Documentation lookup
    PLANNING = "planning"    # Workflow organization
    ANALYSIS = "analysis"    # Code analysis
    DEBUG = "debug"          # Problem investigation


@dataclass
class MCPTool:
    \"\"\"MCP tool with capability metadata.\"\"\"
    name: str
    available: bool
    capability: ToolCapability
    fallback: str | None = None
    use_cases: list[str] | None = None


def detect_mcp_tools() -> dict[str, MCPTool]:
    \"\"\"Detect available MCP tools with intelligent fallback mapping.\"\"\"

    tools = {
        # Reasoning tools
        'sequential_thinking': MCPTool(
            name='sequential_thinking',
            available=True,
            capability=ToolCapability.REASONING,
            fallback=None,
            use_cases=[
                'Complex architectural decisions',
                'Multi-step problem analysis',
                'Iterative problem refinement',
            ]
        ),

        # Research tools
        'context7': MCPTool(
            name='context7',
            available=True,
            capability=ToolCapability.RESEARCH,
            fallback='web_search',
            use_cases=[
                'Library documentation lookup',
                'API reference retrieval',
                'Best practices research',
            ]
        ),
        'web_search': MCPTool(
            name='web_search',
            available=True,
            capability=ToolCapability.RESEARCH,
            fallback=None,
            use_cases=[
                'Latest framework updates',
                'Community best practices',
                'Fallback documentation lookup',
            ]
        ),

        # Planning tools
        'zen_planner': MCPTool(
            name='zen_planner',
            available=True,
            capability=ToolCapability.PLANNING,
            use_cases=[
                'Multi-phase project planning',
                'Migration strategy design',
                'Complex feature breakdown',
            ]
        ),

        # Analysis tools
        'zen_thinkdeep': MCPTool(
            name='zen_thinkdeep',
            available=True,
            capability=ToolCapability.ANALYSIS,
            use_cases=[
                'Architecture review',
                'Performance analysis',
                'Security assessment',
            ]
        ),
        'zen_analyze': MCPTool(
            name='zen_analyze',
            available=True,
            capability=ToolCapability.ANALYSIS,
            use_cases=[
                'Code quality analysis',
                'Pattern detection',
                'Tech debt assessment',
            ]
        ),

        # Debug tools
        'zen_debug': MCPTool(
            name='zen_debug',
            available=True,
            capability=ToolCapability.DEBUG,
            use_cases=[
                'Root cause investigation',
                'Bug reproduction',
                'Performance debugging',
            ]
        ),
        'zen_consensus': MCPTool(
            name='zen_consensus',
            available=True,
            capability=ToolCapability.PLANNING,
            use_cases=[
                'Architecture decision making',
                'Technology selection',
                'Multi-model validation',
            ]
        ),
    }

    return tools


def generate_tool_strategy(tools: dict[str, MCPTool]) -> str:
    \"\"\"Generate intelligent tool usage strategy.\"\"\"

    strategy = ["# MCP Tool Strategy\\n\\n"]

    by_capability = {}
    for tool in tools.values():
        if tool.capability not in by_capability:
            by_capability[tool.capability] = []
        by_capability[tool.capability].append(tool)

    for capability, tool_list in by_capability.items():
        strategy.append(f"## {capability.value.title()} Tools\\n\\n")

        available = [t for t in tool_list if t.available]
        unavailable = [t for t in tool_list if not t.available]

        if available:
            primary = available[0]
            strategy.append(f"**Primary**: `{primary.name}`\\n\\n")

            if primary.use_cases:
                strategy.append("Use when:\\n\\n")
                for use_case in primary.use_cases:
                    strategy.append(f"- {use_case}\\n")
                strategy.append("\\n")

            if primary.fallback:
                fallback_tool = tools.get(primary.fallback)
                if fallback_tool and not fallback_tool.available:
                    strategy.append(f"**Fallback**: Manual {capability.value} (no tools available)\\n\\n")
                elif fallback_tool:
                    strategy.append(f"**Fallback**: `{primary.fallback}`\\n\\n")
        else:
            strategy.append(f"No tools available - manual {capability.value} required\\n\\n")

    return "".join(strategy)


if __name__ == "__main__":
    tools = detect_mcp_tools()

    # Generate strategy document
    strategy = generate_tool_strategy(tools)

    with open('.gemini/mcp-strategy.md', 'w') as f:
        f.write(strategy)

    # Generate availability list
    with open('.gemini/mcp-tools.txt', 'w') as f:
        f.write("Available MCP Tools (Auto-Detected):\\n\\n")
        for tool in tools.values():
            status = "Available" if tool.available else "Not available"
            f.write(f"- {tool.name}: {status}\\n")
            if tool.fallback:
                f.write(f"  Fallback: {tool.fallback}\\n")

    print("MCP tool detection complete")
    print("Generated .gemini/mcp-tools.txt")
    print("Generated .gemini/mcp-strategy.md")
EOF

chmod +x .gemini/tools/detect_mcp.py
python .gemini/tools/detect_mcp.py 2>/dev/null || echo "Python detection script created"
```

---

## PHASE 3: ADAPTIVE INFRASTRUCTURE

### Step 3.1: Create Intelligent Directory Structure

```bash
mkdir -p .gemini/commands
mkdir -p .gemini/tools
mkdir -p .gemini/context
mkdir -p specs/active specs/archive
mkdir -p specs/guides/patterns specs/guides/workflows specs/guides/examples
mkdir -p specs/template-spec/research specs/template-spec/tmp
touch specs/active/.gitkeep specs/archive/.gitkeep
```

**Structure Intelligence**:

- `.gemini/tools/` - Reusable scripts for agents
- `.gemini/context/` - Framework context files
- `specs/guides/patterns/` - Extracted code patterns
- `specs/guides/examples/` - Real implementation examples

### Step 3.2: Create Adaptive Quality Gates

```bash
cat > specs/guides/quality-gates.yaml << 'EOF'
metadata:
  version: "2.0"
  adaptive: true
  description: "Quality gates that adapt to project conventions"

implementation_gates:
  - name: local_tests_pass
    command: "make test"
    fallback: "uv run pytest tests/"
    required: true
    adaptive: true
    description: "All tests must pass before proceeding"

  - name: linting_clean
    command: "make lint"
    fallback: "uv run ruff check ."
    required: true
    description: "Zero linting errors allowed"

  - name: type_checking_pass
    command: "mypy src/"
    required: false
    adaptive: true
    description: "Type checking must pass"

testing_gates:
  - name: coverage_threshold
    threshold: 90
    scope: "modified_modules"
    adaptive: true
    description: "Modified modules must achieve configured coverage"

  - name: test_isolation
    command: "pytest -n auto tests/"
    required: true
    description: "Tests must work in parallel execution"

documentation_gates:
  - name: anti_pattern_scan
    adaptive: true
    rules:
      - pattern: "from __future__ import annotations"
        severity: "error"
        message: "Use explicit stringification instead"
        context: "Project convention - avoid future annotations"

      - pattern: "Optional\\["
        severity: "error"
        message: "Use T | None (PEP 604) instead"
        context: "Modern Python 3.10+ style"

      - pattern: "class Test"
        severity: "warning"
        message: "Use function-based pytest tests"
        context: "Project uses function-based tests"

  - name: pattern_documentation
    description: "New patterns must be captured in specs/guides/patterns/"
    required: true
EOF
```

### Step 3.3: Create Intelligent Workflow Templates

```bash
cat > specs/guides/workflows/intelligent-development.yaml << 'EOF'
workflow_name: "Intelligent Feature Development"
version: "2.0"
adaptive: true

phases:
  - name: "context_analysis"
    duration: "auto"
    agent: "prd"
    steps:
      - name: "load_project_context"
        description: "Read GEMINI.md, existing guides, codebase patterns"
        outputs:
          - "Context understanding document"

      - name: "identify_similar_features"
        description: "Find similar implementations to learn from"
        tools: ["grep", "find", "read"]
        outputs:
          - "Pattern analysis"

      - name: "assess_complexity"
        description: "Determine feature complexity level"
        criteria:
          - "Lines of code impacted"
          - "Number of components affected"
          - "Integration points"
          - "Database schema changes"
        outputs:
          - "Complexity: simple|medium|complex"

      - name: "adapt_workflow"
        description: "Adjust checkpoint count based on complexity"
        adaptive_rules:
          simple: "6 checkpoints"
          medium: "8 checkpoints"
          complex: "10+ checkpoints"

  - name: "planning"
    agent: "prd"
    gemini_command: "/prd {feature-description}"
    adaptive_checkpoints: true
    quality_gates:
      - "context_loaded"
      - "research_complete"
      - "patterns_identified"

  - name: "implementation"
    agent: "expert"
    auto_trigger: false
    adaptive: true
    quality_gates:
      - "local_tests_pass"
      - "linting_clean"
      - "follows_project_patterns"

  - name: "knowledge_capture"
    agent: "docs-vision"
    auto_trigger: true
    description: "Extract and document new patterns"
    outputs:
      - "specs/guides/patterns/{pattern-name}.md"
      - "specs/guides/examples/{example-name}.py"
      - "Updated GEMINI.md"
EOF
```

### Step 3.4: Update .gitignore

```bash
cat >> .gitignore << 'EOF'

# Gemini Agent System
specs/active/
specs/archive/
.gemini/mcp-tools.txt
.gemini/mcp-strategy.md
!specs/active/.gitkeep
!specs/archive/.gitkeep
!specs/guides/
!specs/guides/**/*.md
!specs/guides/**/*.yaml
!specs/template-spec/
!specs/template-spec/**/*.md
EOF
```

---

## PHASE 4: DETECTION AND GENERATION

### Step 4.1: Language Detection

Scan for primary language indicators:

```bash
# Python indicators
test -f pyproject.toml && echo "LANG_PYTHON=true"
test -f setup.py && echo "LANG_PYTHON=true"
test -f requirements.txt && echo "LANG_PYTHON=true"
test -f uv.lock && echo "LANG_PYTHON=true"

# JavaScript/TypeScript indicators
test -f package.json && echo "LANG_JS=true"
test -f tsconfig.json && echo "LANG_TS=true"

# Other languages
test -f Cargo.toml && echo "LANG_RUST=true"
test -f go.mod && echo "LANG_GO=true"
```

### Step 4.2: Framework Detection - Python

Parse pyproject.toml for frameworks:

```bash
# Web frameworks
grep -i "litestar" pyproject.toml 2>/dev/null && echo "PY_LITESTAR=true"
grep -i "fastapi" pyproject.toml 2>/dev/null && echo "PY_FASTAPI=true"
grep -i "flask" pyproject.toml 2>/dev/null && echo "PY_FLASK=true"
grep -i "django" pyproject.toml 2>/dev/null && echo "PY_DJANGO=true"

# Database/ORM
grep -i "sqlalchemy" pyproject.toml 2>/dev/null && echo "PY_SQLALCHEMY=true"
grep -i "advanced-alchemy" pyproject.toml 2>/dev/null && echo "PY_ADVANCED_ALCHEMY=true"

# Testing
grep -i "pytest" pyproject.toml 2>/dev/null && echo "PY_PYTEST=true"
grep -i "pytest-asyncio" pyproject.toml 2>/dev/null && echo "PY_PYTEST_ASYNCIO=true"

# Linting
grep -i "ruff" pyproject.toml 2>/dev/null && echo "PY_RUFF=true"
grep -i "mypy" pyproject.toml 2>/dev/null && echo "PY_MYPY=true"
```

### Step 4.3: Framework Detection - JavaScript/TypeScript

Parse package.json for frameworks:

```bash
# UI Frameworks
grep '"react"' package.json 2>/dev/null && echo "JS_REACT=true"
grep '"vue"' package.json 2>/dev/null && echo "JS_VUE=true"
grep '"svelte"' package.json 2>/dev/null && echo "JS_SVELTE=true"
grep '"@angular/core"' package.json 2>/dev/null && echo "JS_ANGULAR=true"

# Meta-frameworks
grep '"next"' package.json 2>/dev/null && echo "JS_NEXT=true"
grep '"nuxt"' package.json 2>/dev/null && echo "JS_NUXT=true"

# Build tools
grep '"vite"' package.json 2>/dev/null && echo "JS_VITE=true"

# Integration
grep '"@inertiajs"' package.json 2>/dev/null && echo "JS_INERTIA=true"
grep '"htmx.org"' package.json 2>/dev/null && echo "JS_HTMX=true"

# Testing
grep '"vitest"' package.json 2>/dev/null && echo "JS_VITEST=true"
grep '"jest"' package.json 2>/dev/null && echo "JS_JEST=true"

# Linting
grep '"@biomejs"' package.json 2>/dev/null && echo "JS_BIOME=true"
grep '"eslint"' package.json 2>/dev/null && echo "JS_ESLINT=true"
```

### Step 4.4: Build System Detection

```bash
# Makefile
test -f Makefile && echo "BUILD_MAKE=true"
grep "test:" Makefile 2>/dev/null && echo "TEST_CMD_MAKE=true"
grep "lint:" Makefile 2>/dev/null && echo "LINT_CMD_MAKE=true"

# npm scripts
grep '"test"' package.json 2>/dev/null && echo "TEST_CMD_NPM=true"
grep '"lint"' package.json 2>/dev/null && echo "LINT_CMD_NPM=true"

# Python package managers
test -f uv.lock && echo "PKG_UV=true"
test -f poetry.lock && echo "PKG_POETRY=true"
```

### Step 4.5: Code Style Detection

```bash
# Python type hint style
grep -r "Optional\\[" src/ 2>/dev/null | head -5 && echo "STYLE_OPTIONAL=true"
grep -r "| None" src/ 2>/dev/null | head -5 && echo "STYLE_PEP604=true"

# Future annotations
grep -r "from __future__ import annotations" src/ 2>/dev/null && echo "STYLE_FUTURE_ANNOTATIONS=true"

# Test style
grep -r "class Test" tests/ 2>/dev/null | head -3 && echo "STYLE_CLASS_TESTS=true"
grep -r "^def test_" tests/ 2>/dev/null | head -3 && echo "STYLE_FUNC_TESTS=true"
```

---

## PHASE 5: GENERATE GEMINI.md

Create the main Gemini instructions file:

```bash
cat > .gemini/GEMINI.md << 'EOF'
# Gemini Agent System for {PROJECT_NAME}

This document provides behavioral instructions and project context for Gemini CLI agents.

---

## BEHAVIORAL REQUIREMENTS (READ FIRST)

### Core Principles

1. **Verify Before Acting** - Never assume; always confirm understanding
2. **Research Before Implementing** - Search codebase and docs first
3. **Follow Existing Patterns** - Match the style of surrounding code
4. **Ask When Uncertain** - Questions are better than wrong assumptions

### Before ANY Code Changes

You MUST complete these steps before modifying source code:

1. **Verify Understanding**
   - Restate the task in your own words
   - Identify what success looks like
   - List the components that will be affected

2. **Search First**
   - Use `grep`/`find` to locate relevant existing code
   - Read similar implementations in the codebase
   - Check `specs/guides/` for documented patterns

3. **Check Patterns**
   - Read existing code that does similar things
   - Match the naming conventions used
   - Follow the error handling patterns

### STOP Conditions

**Stop and ask the user if**:

- More than 3 files need modification without explicit approval
- You cannot find similar patterns in the codebase
- The technical approach is unclear
- Requirements seem contradictory or ambiguous

---

## Project Overview

- **Name**: {PROJECT_NAME}
- **Description**: {PROJECT_DESCRIPTION}
- **Languages**: {LANGUAGES}
- **Frameworks**: {FRAMEWORKS}
- **Testing**: {TEST_FRAMEWORKS}
- **Linting**: {LINT_TOOLS}

## Code Style Requirements (CRITICAL)

### Python

| Rule | Standard |
|------|----------|
| Type hints | PEP 604: `T | None` |
| Future annotations | **NEVER** - no `from __future__ import annotations` |
| Docstrings | Google style |
| Line length | 120 characters |
| Tests | Function-based only (no `class Test...`) |

### TypeScript

- Biome for formatting/linting
- Strict mode enabled
- Vitest for testing

## Checkpoint-Based Workflow

### Feature Lifecycle

1. **Planning (`/prd`)**: Create Product Requirements Document
2. **Implementation (`/implement`)**: Write code based on PRD
3. **Testing (`/test`)**: Create comprehensive test suite
4. **Review (`/review`)**: Verify quality gates and archive

### Quality Gates

All code must pass:

- **Tests**: `make test` - All tests passing
- **Linting**: `make lint` - Zero errors
- **Coverage**: 90%+ for modified modules
- **Anti-patterns**: No violations

## MCP Tools Available

### Context7 (Library Documentation)

```python
mcp__context7__resolve-library-id(libraryName="litestar")
mcp__context7__get-library-docs(
    context7CompatibleLibraryID="/litestar-org/litestar",
    topic="plugins middleware",
    mode="code"
)
```

### Sequential Thinking (Complex Analysis)

```python
mcp__sequential-thinking__sequentialthinking(
    thought="Step 1: Analyze the requirement",
    thought_number=1,
    total_thoughts=10,
    next_thought_needed=True
)
```

### Zen Tools

- `mcp__zen__planner` - Multi-step planning
- `mcp__zen__thinkdeep` - Architectural analysis
- `mcp__zen__debug` - Systematic debugging
- `mcp__zen__analyze` - Code analysis
- `mcp__zen__consensus` - Multi-model decisions

## Remember

1. **Read before writing** - Always read existing code first
2. **Match existing patterns** - Don't invent new conventions
3. **Test everything** - 90%+ coverage required
4. **Document decisions** - Explain non-obvious choices
5. **Ask when uncertain** - Questions prevent mistakes
EOF
```

---

## PHASE 6: GENERATE INTELLIGENT COMMANDS

### Generate prd.toml

Create the PRD command with intelligence enhancements:

```bash
cat > .gemini/commands/prd.toml << 'TOML_CONTENT'
description = "Create a comprehensive Product Requirements Document (Intelligent Edition)"
prompt = \"\"\"
You are the PRD Agent with INTELLIGENCE ENHANCEMENTS.

## INTELLIGENCE LAYER

Before starting checkpoints, activate intelligence mode:

1. **Read MCP Strategy**: Load `.gemini/mcp-strategy.md` for tool selection guidance
2. **Learn from Codebase**: Read 3-5 similar implementations before planning
3. **Assess Complexity**: Determine if this is simple/medium/complex feature
4. **Adapt Workflow**: Adjust checkpoint depth based on complexity assessment

## CRITICAL RULES

1. **CONTEXT FIRST** - You MUST read existing patterns before planning new ones
2. **NO CODE MODIFICATION** - You MUST NOT modify any source code during PRD phase
3. **WORKSPACE FIRST** - You MUST create workspace BEFORE starting research
4. **INTELLIGENT TOOL USE** - Check `.gemini/mcp-strategy.md` for tool selection
5. **PATTERN LEARNING** - Identify 3-5 similar features and learn from them
6. **ADAPTIVE DEPTH** - Simple features: 6 checkpoints, Medium: 8, Complex: 10+
7. **RESEARCH GROUNDED** - Minimum 2000+ words of research
8. **COMPREHENSIVE PRD** - Minimum 3200+ words PRD with specific acceptance criteria
9. **GIT VERIFICATION** - Verify git status shows no src/ changes at end

---

## Adaptive Checkpoints

### Checkpoint 0: Intelligence Bootstrap

**Load project intelligence:**

1. Read `GEMINI.md` - Project overview, tech stack, standards
2. Read `.gemini/mcp-strategy.md` - Tool selection guide
3. Read `specs/guides/architecture.md` - System patterns
4. Read `specs/guides/code-style.md` - Code standards
5. Read `specs/guides/patterns/README.md` - Pattern library

**Learn from existing implementations:**

```bash
# Find similar features
grep -r "class.*Plugin" src/ | head -5
grep -r "class.*Config" src/ | head -5

# Read 3 example files to understand patterns
```

**Assess feature complexity:**

- **Simple**: Single file, config change -> 6 checkpoints
- **Medium**: New service/adapter, 2-3 files -> 8 checkpoints
- **Complex**: Architecture change, 5+ files -> 10+ checkpoints

### Checkpoint 1: Requirement Analysis

Understand the user's request and identify similar implementations.

### Checkpoint 2: Workspace Creation

```bash
mkdir -p specs/active/{slug}/research
mkdir -p specs/active/{slug}/tmp
mkdir -p specs/active/{slug}/patterns
touch specs/active/{slug}/prd.md
touch specs/active/{slug}/tasks.md
touch specs/active/{slug}/recovery.md
```

### Checkpoint 3: Deep Analysis

Use Sequential Thinking (15+ thoughts) or `zen_thinkdeep` for comprehensive analysis.

### Checkpoint 4: Research Best Practices

Use Context7 for library documentation. Minimum 2000+ words documented.

### Checkpoint 5: Write Comprehensive PRD

Minimum 3200+ words with specific acceptance criteria.

### Checkpoint 6: Task Breakdown

Create actionable task list adapted to complexity.

### Checkpoint 7: Recovery Guide

Create resumption instructions with intelligence context.

### Checkpoint 8: Git Verification

Verify no source code was modified.

**Feature to plan**: {user_request}
\"\"\"
TOML_CONTENT
```

### Generate implement.toml

```bash
cat > .gemini/commands/implement.toml << 'TOML_CONTENT'
description = "Implement a feature from an existing PRD (Intelligent Edition)"
prompt = \"\"\"
You are the Expert Agent with INTELLIGENCE ENHANCEMENTS.

## INTELLIGENCE LAYER

1. **Read Intelligence Context**: Load pattern analysis from `specs/active/{slug}/patterns/`
2. **Review Similar Features**: Read the 3-5 similar implementations identified in PRD
3. **Load Pattern Library**: Read relevant patterns from `specs/guides/patterns/`
4. **Check Tool Strategy**: Consult `.gemini/mcp-strategy.md` for decisions

## CRITICAL RULES

1. **PATTERN COMPLIANCE** - Follow patterns from similar features
2. **PRD MUST EXIST** - Verify PRD workspace exists and is complete
3. **NO NEW FEATURES** - ONLY implement what's specified in the PRD
4. **LOCAL TESTS REQUIRED** - Run local tests before proceeding
5. **PATTERN EXTRACTION** - Document any new patterns discovered
6. **DEEP RESEARCH** - If complexity > 5, use `sub-agents` (simulated via Task) or Deep Research before coding.

## Checkpoints

### Checkpoint 0: Intelligence Bootstrap
Load project context and feature-specific patterns.

### Checkpoint 1: PRD Verification
Verify workspace exists, read PRD and patterns.

### Checkpoint 2: Pattern Deep Dive & Research
Read and analyze similar implementations.
**If unsure**: Use `Task` to research or `sequential_thinking` to plan.

### Checkpoint 3: Implementation Planning
Create detailed plan following patterns (NO CODE YET).

### Checkpoint 4: Code Implementation
Write code following project patterns and standards.

### Checkpoint 5: Local Testing
Run tests and linting. Fix all errors.

### Checkpoint 6: Pattern Extraction
Document any new patterns discovered.

### Checkpoint 7: Progress Update
Update tasks.md and recovery.md.

### Checkpoint 8: Final Verification
Run full test suite. Ready for review.

**Implementing**: specs/active/{slug}
\"\"\"
TOML_CONTENT
```

### Generate sync-guides.toml

```bash
cat > .gemini/commands/sync-guides.toml << 'TOML_CONTENT'
# Command: /sync-guides
prompt = \"\"\"
You are the Guides Agent for litestar-vite. Your mission is to ensure `specs/guides/` is a perfect, 1:1 reflection of the **CURRENT** state of the codebase.

**Prime Directive: The guides MUST only document what is in the code NOW.**

-   **NO HISTORY**: Don't explain what code *used* to be.
-   **NO BEFORE-AND-AFTER**: No migration paths or version comparisons.
-   **NO OUTDATED CONTENT**: Delete anything out of date without hesitation.
-   **RUTHLESS ACCURACY**: If it's not in the code, it's not in the guides.

**Your Core Workflow (Sequential & Uncompromising)**:

## Phase 1: Deep Code Analysis (The Source of Truth)

1.  **Map Codebase**:
    - List ALL public classes in `src/py/litestar_vite`.
    - List ALL public functions in `src/py/litestar_vite`.
    - List ALL configuration options in `config.py`.
    - List ALL exported functions in `src/js/src`.

2.  **Verify Templates**:
    - Check `src/py/litestar_vite/templates/` for current structure.
    - Note defaults: `resources/` for Inertia, `src/` for others.

## Phase 2: Deep Guide Analysis

1.  **Read All Guides**: `specs/guides/architecture.md`, `specs/guides/code-style.md`, `specs/guides/testing.md`, etc.
2.  **Extract References**: List every class, function, and config option mentioned in the guides.

## Phase 3: Discrepancy Detection & Correction

**Pattern 1: Dead Code (Mentioned in Guide, Missing in Code)**
- **Check**: For every item in Guide Inventory, verify it exists in Code Inventory.
- **Action**: If missing -> **DELETE** from guide immediately.

**Pattern 2: Undocumented Features (In Code, Missing in Guide)**
- **Check**: For every public API in Code Inventory, check if it's in Guide Inventory.
- **Action**: If missing -> **CREATE** documentation in relevant guide.

**Pattern 3: Configuration Drift**
- **Check**: Compare default values in `config.py` vs guides.
- **Action**: **UPDATE** guide to match code exactly.

## Phase 4: Execution & Verification

1.  **Apply Edits**: Update markdown files.
2.  **Build Docs**: `make docs` (if available).
3.  **Verify**: `make lint` and `make test` to ensure docs didn't break anything (e.g. doctests).

**Acceptance Criteria**:
- [ ] 100% accuracy: Every statement matches code
- [ ] Zero outdated content
- [ ] All public APIs documented
- [ ] `make lint` passes

Begin synchronization now. Be ruthless. The guides must be pure.
\"\"\"
TOML_CONTENT
```

### Generate sync-llms-txt.toml

```bash
cat > .gemini/commands/sync-llms-txt.toml << 'TOML_CONTENT'
# Command: /sync-llms-txt
prompt = \"\"\"
You are an LLM documentation synchronization agent. Your mission is to ensure `llms.txt` and `llms-full.txt` are perfectly synchronized with the **CURRENT** state of any codebase.

**Prime Directive: The llms.txt files MUST only document what is in the code NOW.**

-   **NO HISTORY**: Don't document what code *used* to be.
-   **NO OUTDATED CONTENT**: Delete anything out of date without hesitation.
-   **OPTIMIZE FOR SEARCHABILITY**: llms.txt must be easily searchable by LLMs.
-   **COMPLETE PATTERNS**: llms-full.txt must have ALL necessary patterns.

## Phase 0: Project Discovery & Inventory

**1. Detect Project Type**:
   - Check `pyproject.toml`, `package.json`, `Cargo.toml`, etc.
   - Identify frameworks (Litestar, Vite, React, etc.).

**2. Build Code Inventory**:
   - **Public APIs**: Scan `src/` for public classes/functions/exports.
   - **Configuration**: Scan config files for options/env vars.
   - **Examples**: List all runnable examples.

**3. Build Documentation Inventory**:
   - Read `llms.txt` and `llms-full.txt`.
   - Extract every API, config option, and example mentioned.

## Phase 1: Strict Validation (The Filter)

**1. Dead Code Check**:
   - For EACH item in Documentation Inventory: **Grep** the codebase.
   - If 0 matches -> **MARK FOR DELETION**.

**2. Dead Link Check**:
   - Extract all URLs.
   - Verify they are reachable (200 OK).
   - If broken -> **REMOVE**.

**3. Config Drift Check**:
   - Compare defaults in docs vs code.
   - If different -> **MARK FOR UPDATE**.

## Phase 2: Execution (Add, Remove, Update)

**1. REMOVE Invalid Content**:
   - Delete all items marked for deletion.
   - Remove deprecated APIs.

**2. ADD Missing Content**:
   - Add undocumented public APIs found in Code Inventory.
   - Add new configuration options.
   - Add new examples.

**3. UPDATE Stale Content**:
   - Refresh API signatures.
   - Update version numbers.
   - Fix code examples to match current syntax.

## Phase 3: Optimization

**1. llms.txt Optimization**:
   - Ensure < 2000 tokens.
   - Prioritize: Install > Basic Config > Core APIs.
   - Use clear headers and keywords.

**2. llms-full.txt Completeness**:
   - Ensure all Universal Patterns are covered (Install, Config, Error Handling).
   - Ensure Language-Specific Patterns are covered.

## Phase 4: Final Verification

- [ ] All code examples are valid syntax.
- [ ] No dead links.
- [ ] No dead code references.
- [ ] Token limits respected.

Begin synchronization now. Be thorough and ruthless.
\"\"\"
TOML_CONTENT
```

### Generate test.toml

```bash
cat > .gemini/commands/test.toml << 'TOML_CONTENT'
description = "Run comprehensive tests for a feature (Intelligent Edition)"
prompt = \"\"\"
You are the Testing Agent with INTELLIGENCE ENHANCEMENTS.

## INTELLIGENCE LAYER

1. **Read Pattern Library**: Load test patterns from `specs/guides/patterns/test-*.md`
2. **Learn from Similar Tests**: Read test files for similar features
3. **Load MCP Strategy**: Use `.gemini/mcp-strategy.md` for tool selection
4. **Assess Test Complexity**: Determine coverage needs based on feature complexity

## CHECKPOINT EXECUTION

### Checkpoint 0: Intelligence Bootstrap
Assess test complexity. Simple: 6 checkpoints, Medium: 8, Complex: 9+.

### Checkpoint 1: Unit Test Creation
Create unit tests following existing patterns.

### Checkpoint 2: Integration Test Setup
Determine coverage scope and create test structure.

### Checkpoint 3: Integration Tests
Create tests for each affected component.

### Checkpoint 4: Edge Case Testing
Create tests for boundary conditions and error cases.

### Checkpoint 5: Coverage Verification
Run coverage report. Unit >= 90%, Integration >= 80%.

### Checkpoint 6: Final Test Suite Execution
Run complete test suite. No regressions.

**Testing**: specs/active/{slug}
\"\"\"
TOML_CONTENT
```

### Generate review.toml

```bash
cat > .gemini/commands/review.toml << 'TOML_CONTENT'
description = "Run quality gates, pattern extraction, and workspace archival"
prompt = \"\"\"
You are the Docs & Vision Agent with INTELLIGENCE ENHANCEMENTS.

## INTELLIGENCE LAYER

1. **Read Pattern Library**: Load existing patterns from `specs/guides/patterns/`
2. **Load MCP Strategy**: Use `.gemini/mcp-strategy.md` for tool selection
3. **Prepare Pattern Extraction**: Identify new reusable patterns
4. **Load Quality Gates**: Read `specs/guides/quality-gates.yaml`

## SUB-PHASES

1. **Documentation Update** (Checkpoints 1-2)
2. **Quality Gate Validation** (Checkpoint 3)
3. **Knowledge Capture** (Checkpoint 4)
4. **Re-validation** (Checkpoint 5)
5. **Workspace Archive** (Checkpoint 6)

## CHECKPOINTS

### Checkpoint 0: Intelligence Bootstrap
Review implementation artifacts and plan pattern extraction.

### Checkpoint 1: Documentation Update
Update feature documentation and guides.

### Checkpoint 2: Update GEMINI.md
Add new patterns if discovered.

### Checkpoint 3: Quality Gate Validation
Run linting, type checking, tests, and docs build.

### Checkpoint 4: Pattern Extraction
Extract new patterns to specs/guides/patterns/.

### Checkpoint 5: Re-validation
Re-run tests after documentation updates.

### Checkpoint 6: Archive Workspace
Clean tmp/, create COMPLETION-SUMMARY.md, move to specs/archive/.

**Reviewing**: specs/active/{slug}
\"\"\"
TOML_CONTENT
```

### Generate explore.toml

```bash
cat > .gemini/commands/explore.toml << 'TOML_CONTENT'
description = "Explore and understand the codebase structure"
prompt = \"\"\"
Exploring: {topic}

## Search Commands

```bash
# Find files
find . -name "*{topic}*" -type f

# Search content
grep -r "{topic}" src/

# Find classes
grep -r "class.*{topic}" src/

# Find functions
grep -r "def.*{topic}" src/
```

## Exploration Guidelines

1. Start with directory structure overview
2. Identify entry points and main components
3. Trace data flow through the system
4. Document dependencies and relationships
5. Note patterns and conventions used

Explore the relevant files and explain the architecture.
\"\"\"
TOML_CONTENT
```

### Generate fix-issue.toml

```bash
cat > .gemini/commands/fix-issue.toml << 'TOML_CONTENT'
description = "Fix a GitHub issue"
prompt = \"\"\"
Fixing issue: #{issue_number}

## Workflow

1. Fetch issue details: `gh issue view {issue_number}`
2. Search for affected code
3. Read related files and understand context
4. Implement fix following code standards
5. Run tests: `make test`
6. Run linting: `make lint`
7. Create commit with issue reference

## Code Standards

- Type hints: `T | None` (PEP 604)
- NO future annotations
- Google-style docstrings
- Function-based tests only
\"\"\"
TOML_CONTENT
```

---

## PHASE 7: GENERATE CONTEXT FILES

Generate framework context files for detected frameworks:

### Litestar Context

```bash
cat > .gemini/context/litestar.md << 'EOF'
# Litestar Framework Context

Expert knowledge for Litestar Python web framework.

## Plugin Development

```python
from litestar.plugins import InitPluginProtocol

class MyPlugin(InitPluginProtocol):
    def on_app_init(self, app_config: AppConfig) -> AppConfig:
        return app_config
```

## Route Handlers

```python
from litestar import get, post

@get("/items/{item_id:int}")
async def get_item(item_id: int) -> Item:
    return await fetch_item(item_id)
```

## Context7 Lookup

```python
mcp__context7__get-library-docs(
    context7CompatibleLibraryID="/litestar-org/litestar",
    topic="plugins middleware",
    mode="code"
)
```
EOF
```

### React Context

```bash
cat > .gemini/context/react.md << 'EOF'
# React Framework Context

Expert knowledge for React 18+ with TypeScript.

## Component Patterns

```tsx
export function ItemList({ items }: Props) {
  const [selected, setSelected] = useState<Item | null>(null);
  return (
    <ul>
      {items.map(item => (
        <li key={item.id}>{item.name}</li>
      ))}
    </ul>
  );
}
```

## Context7 Lookup

```python
mcp__context7__get-library-docs(
    context7CompatibleLibraryID="/facebook/react",
    topic="hooks components",
    mode="code"
)
```
EOF
```

### Vue Context

```bash
cat > .gemini/context/vue.md << 'EOF'
# Vue 3 Framework Context

Expert knowledge for Vue 3 Composition API.

## Component Pattern

```vue
<script setup lang="ts">
import { ref, computed } from 'vue';

const items = ref<Item[]>([]);
const filtered = computed(() => items.value.filter(i => i.active));
</script>

<template>
  <ul>
    <li v-for="item in filtered" :key="item.id">{{ item.name }}</li>
  </ul>
</template>
```

## Context7 Lookup

```python
mcp__context7__get-library-docs(
    context7CompatibleLibraryID="/vuejs/core",
    topic="composition-api",
    mode="code"
)
```
EOF
```

### pytest Context

```bash
cat > .gemini/context/pytest.md << 'EOF'
# pytest Testing Context

## Basic Tests (Function-Based Only)

```python
def test_addition():
    assert 1 + 1 == 2

@pytest.fixture
def sample_data():
    return {"key": "value"}

@pytest.mark.asyncio
async def test_async():
    result = await async_op()
    assert result is not None
```

## Context7 Lookup

```python
mcp__context7__get-library-docs(
    context7CompatibleLibraryID="/pytest-dev/pytest",
    topic="fixtures async",
    mode="code"
)
```
EOF
```

### Vite Context

```bash
cat > .gemini/context/vite.md << 'EOF'
# Vite Build Tool Context

## Configuration

```typescript
import { defineConfig } from 'vite';

export default defineConfig({
  plugins: [],
  server: {
    proxy: { '/api': 'http://localhost:8000' }
  }
});
```

## Context7 Lookup

```python
mcp__context7__get-library-docs(
    context7CompatibleLibraryID="/vitejs/vite",
    topic="configuration plugins",
    mode="code"
)
```
EOF
```

### Vitest Context

```bash
cat > .gemini/context/vitest.md << 'EOF'
# Vitest Testing Context

## Basic Tests

```typescript
import { describe, it, expect, vi } from 'vitest';

describe('Feature', () => {
  it('works', () => {
    expect(1 + 1).toBe(2);
  });
});
```

## Context7 Lookup

```python
mcp__context7__get-library-docs(
    context7CompatibleLibraryID="/vitest-dev/vitest",
    topic="mocking",
    mode="code"
)
```
EOF
```

---

## PHASE 8: GENERATE SETTINGS

Create the Gemini settings file:

```bash
cat > .gemini/settings.json << 'EOF'
{
  "context": {
    "fileName": ["GEMINI.md"],
    "includeDirectories": [".gemini/context", "specs/guides"],
    "loadFromIncludeDirectories": true
  },
  "model": {
    "name": "gemini-2.5-pro"
  },
  "mcpServers": {
    "context7": {
      "command": "npx",
      "args": ["-y", "@upstash/context7-mcp"],
      "trust": true
    },
    "sequential-thinking": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-sequential-thinking"],
      "trust": true
    }
  }
}
EOF
```

---

## PHASE 9: KNOWLEDGE BASE INITIALIZATION

### Create Pattern Library Index

```bash
cat > specs/guides/patterns/README.md << 'EOF'
# Project Patterns

Auto-extracted patterns from codebase for agent guidance.

## Architectural Patterns

- Plugin Pattern - Litestar plugin development
- Config Pattern - Configuration management
- Middleware Pattern - Request/response processing

## Code Patterns

- Error Handling - Exception types and handling
- Async/Await - Async operation patterns
- Type Annotations - PEP 604 type hints

## Testing Patterns

- Unit Test Structure - Function-based tests
- Integration Test Setup - Multi-component tests
- Test Fixtures - Data preparation

---

*This index is maintained automatically by agents during feature development.*
EOF
```

---

## PHASE 10: ALIGNMENT MODE

When existing bootstrap is detected:

### Step 10.1: Inventory Existing Configuration

```bash
ls .gemini/commands/*.toml 2>/dev/null
ls .gemini/context/*.md 2>/dev/null
head -5 .gemini/GEMINI.md 2>/dev/null | grep "Version"
```

### Step 10.2: Identify Missing Components

Compare existing vs expected core commands and context files.

### Step 10.3: Preserve Custom Content

Before updating any file, identify and preserve custom sections.

### Step 10.4: Update Outdated Patterns

Check for outdated patterns and offer to update with user confirmation.

### Step 10.5: Merge and Update

Generate new content, insert preserved custom content, write merged files.

---

## PHASE 11: VERIFICATION

### Validate Generated Files

```bash
test -f .gemini/GEMINI.md && echo "GEMINI.md created"
test -d .gemini/commands && echo ".gemini/commands/ created"
test -d .gemini/context && echo ".gemini/context/ created"
test -f .gemini/settings.json && echo "settings.json created"
test -d specs/guides && echo "specs/guides/ created"

echo "Commands: $(ls .gemini/commands/*.toml 2>/dev/null | wc -l)"
echo "Contexts: $(ls .gemini/context/*.md 2>/dev/null | wc -l)"
```

### Summary Report

```
Intelligent Bootstrap Complete

Intelligence Layer:
- MCP tool detection with fallback strategies
- Pattern extraction from existing codebase
- Adaptive quality gates
- Context-aware workflows
- Knowledge base initialized

Adaptive Features:
- Checkpoint counts scale with complexity
- Tool selection based on availability
- Quality gates adapt to project norms
- Workflows adjust to feature scope

Knowledge Capture:
- Pattern extraction automated
- Example code documented
- Guides continuously updated
- Agent memory persists across sessions

Next Steps:
  1. Run `/prd "feature description"` - System adapts to complexity
  2. Agents learn from existing code before creating new patterns
  3. Knowledge base grows with each completed feature
  4. Future agents inherit all learnings automatically
```

---

## EXECUTION INSTRUCTIONS

Now execute this bootstrap:

1. **Run Intelligent Analysis** (Phase 1-2)
2. **Create Adaptive Infrastructure** (Phase 3)
3. **Detect Languages and Frameworks** (Phase 4)
4. **Generate GEMINI.md** (Phase 5)
5. **Generate Intelligent Commands** (Phase 6)
6. **Generate Context Files** (Phase 7)
7. **Generate Settings** (Phase 8)
8. **Initialize Knowledge Base** (Phase 9)
9. **If existing bootstrap**: Run Alignment (Phase 10)
10. **Run Verification** (Phase 11)
11. **Report Results**

**Begin intelligent bootstrap now.**
"""
